{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5026615a",
   "metadata": {},
   "source": [
    "# Computational Social Science Project #2 \n",
    "\n",
    "**Name:** Kylee Hoffman\n",
    "\n",
    "*Semester:* Fall 2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7920223d",
   "metadata": {},
   "source": [
    "## 1. Introduction/Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013cd72b",
   "metadata": {},
   "source": [
    "#### a) Import relevant libraries\n",
    "Here are some libraries you will need to get started. Along the way you may need to add more. Best practice is to add them here at the top of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca2b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# import libraries\n",
    "#-----------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# set seed\n",
    "np.random.seed(273)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b23b0",
   "metadata": {},
   "source": [
    "#### b) Read in and inspect data frame \n",
    "Read in the data frame and look at some of its attributes. Read in the data contained in the projoect folder: \"Diabetes with Population Info by County 2017.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171cd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# read in and inspect data frame\n",
    "#-----------\n",
    "diabetes = pd.read_csv(\"Diabetes with Population Info by County 2017.csv\", \n",
    "                       dtype={\"CountyFIPS\": str}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca77b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# look at shape\n",
    "#-----------\n",
    "# look at the dimensions of the diabetes data frame\n",
    "print('shape: ', diabetes.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91328e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# set pandas parameters\n",
    "#-----------\n",
    "# tells pandas how many rows to display when printing so results don't get truncated\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# look at the data types for each column in diabetes df (likely be located under each row bc column names are long)\n",
    "print('data types:', diabetes.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e77f8b",
   "metadata": {},
   "source": [
    "Immediately, we see that some of the features that should be numeric (e.g., Diabetes_Number, Obesity_Number,  and Physical_Inactivity_Number) are not. We can check to see what the non-numeric values are in a column where we are expecting numeric information with a combination of `str.isnumeric()` and `unique()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72315139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# identify non-numeric features\n",
    "#-----------\n",
    "# Return rows where the column \"Diabetes_Number\" is non-numeric and get the unique values of these rows\n",
    "# the \"~\" below in front of diabetes negates the str.isnumeric() so it only takes non-numeric values\n",
    "print(diabetes[~diabetes['Diabetes_Number'].str.isnumeric()]['Diabetes_Number'].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e47c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Now do the same as above, but for \"Obesity_Number\"\n",
    "#-----------\n",
    "\n",
    "print(diabetes[~diabetes['Obesity_Number'].str.isnumeric()]['Obesity_Number'].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Now do the same as above, but for \"Physical_Inactivity_Number\" \n",
    "#-----------\n",
    "\n",
    "print(diabetes[~diabetes['Physical_Inactivity_Number'].str.isnumeric()]['Physical_Inactivity_Number'].unique()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b705636f",
   "metadata": {},
   "source": [
    "These values (\"Suppresssed\" and \"No Data\") contained in the two respective columns are coercing these features to objects instead of them being  integers. Let's drop those rows in the next section, and also recode \"Physical_Inactivity_Number\" feature to be an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2a442a",
   "metadata": {},
   "source": [
    "#### c. Recode variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31fe962",
   "metadata": {},
   "source": [
    "Convert 'Diabetes_Number', 'Obesity_Number', and 'Physical_Inactivity_Number' to integers below so we can use them in our analysis. Also fill in the object type we want to recode 'sex and age_total population_65 years and over_sex ratio (males per 100 females)' too (you'll have to scroll all the way over to the right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4acf34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Recode variables\n",
    "#-----------\n",
    "\n",
    "# Diabetes\n",
    "# ----------\n",
    "# keep only useful info about target feature\n",
    "diabetes = diabetes[diabetes['Diabetes_Number']!=\"Suppressed\"] \n",
    "# convert to integer\n",
    "diabetes['Diabetes_Number'] = diabetes['Diabetes_Number'].astype(int) \n",
    "\n",
    "# Obesity\n",
    "# ----------\n",
    "diabetes = diabetes[diabetes['Obesity_Number']!=\"No Data\"] \n",
    "diabetes['Obesity_Number'] = diabetes['Obesity_Number'].astype(int) \n",
    "\n",
    "# Physical Inactivity\n",
    "# ----------\n",
    "diabetes = diabetes[diabetes['Physical_Inactivity_Number']!=\"No Data\"] \n",
    "diabetes['Physical_Inactivity_Number'] = diabetes['Physical_Inactivity_Number'].astype(int) \n",
    "\n",
    "# Some final changes \n",
    "# ----------\n",
    "# 65+ sex ratio had one \"-\" in it so let's drop that row first\n",
    "diabetes = diabetes[diabetes['sex and age_total population_65 years and over_sex ratio (males per 100 females)']!= \"-\"]\n",
    "\n",
    "# change to numeric from string, since it originally included the \"-\", which made it a string\n",
    "# you'll have to decide whether to make it integer or float \n",
    "diabetes['sex and age_total population_65 years and over_sex ratio (males per 100 females)'] = diabetes['sex and age_total population_65 years and over_sex ratio (males per 100 females)'].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a6850c",
   "metadata": {},
   "source": [
    "We should probably scale our count variables to be proportional to county population. We create the list 'rc_cols' to select all the features we want to rescale, and then use the `.div()` method to avoid typing out every single column we want to recode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb2299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Scale to county populations\n",
    "#-----------\n",
    "\n",
    "# select count variables to recode to percentages; make sure we leave out ratios and our population variable \n",
    "# because these don't make sense to scale by population\n",
    "rc_cols = [col for col in diabetes.columns if col not in ['County', 'State', 'CountyFIPS', \n",
    "                                                        'sex and age_total population_65 years and over_sex ratio (males per 100 females)', \n",
    "                                                        'sex and age_total population_sex ratio (males per 100 females)', \n",
    "                                                        'sex and age_total population_18 years and over_sex ratio (males per 100 females)',  \n",
    "                                                        'race_total population']]\n",
    "           \n",
    "# recode all selected columns to numeric\n",
    "diabetes[rc_cols] = diabetes[rc_cols].apply(pd.to_numeric, errors='coerce') \n",
    "\n",
    "# divide all columns but those listed above by total population to calculate rates\n",
    "diabetes[rc_cols] = diabetes[rc_cols].div(diabetes['race_total population'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9e1fe2",
   "metadata": {},
   "source": [
    "Let's check our work. Are all rates bounded by 0 and 1 as expected? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f8f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# check\n",
    "#-----------\n",
    "# set pandas options\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# inspect recoded values\n",
    "diabetes_summary = diabetes.describe().transpose() # note we use the transpose method rather than .T because this object is not a numpy array\n",
    "  \n",
    "# check recoding \n",
    "with pd.option_context('display.max_rows', 100, 'display.max_columns', None): \n",
    "    display(diabetes_summary.iloc[ : ,[0,1,3,7]]) # select which columns in the summary table we want to present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dcc070",
   "metadata": {},
   "source": [
    "#### d. Check for duplicate columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acce0aa",
   "metadata": {},
   "source": [
    "There are a lot of columns in this data frame. Let's see if there are any are duplicates. Note that Pandas will not allow them to have the same exact column name, so they will likely be distinct on column name but will be copies otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700163cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check for duplicate columns\n",
    "#-----------\n",
    "# source: https://thispointer.com/how-to-find-drop-duplicate-columns-in-a-dataframe-python-pandas/ \n",
    "def getDuplicateColumns(df):\n",
    "    '''\n",
    "    Get a list of duplicate columns.\n",
    "    It will iterate over all the columns in dataframe and find the columns whose contents are duplicate.\n",
    "    :param df: Dataframe object\n",
    "    :return: List of columns whose contents are duplicates.\n",
    "    '''\n",
    "    duplicateColumnNames = set()\n",
    "    # Iterate over all the columns in dataframe\n",
    "    for x in range(df.shape[1]):\n",
    "        # Select column at xth index.\n",
    "        col = df.iloc[:, x]\n",
    "        # Iterate over all the columns in DataFrame from (x+1)th index till end\n",
    "        for y in range(x + 1, df.shape[1]):\n",
    "            # Select column at yth index.\n",
    "            otherCol = df.iloc[:, y]\n",
    "            # Check if two columns at x 7 y index are equal\n",
    "            if col.equals(otherCol):\n",
    "                duplicateColumnNames.add(df.columns.values[y])\n",
    "    return list(duplicateColumnNames)\n",
    "\n",
    "duplicateColumnNames = list(getDuplicateColumns(diabetes))\n",
    "print('Duplicate Columns are as follows: ')\n",
    "duplicateColumnNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba3a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# drop columns from duplicates list\n",
    "#-----------\n",
    "diabetes = diabetes.drop(columns=duplicateColumnNames) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a85ec3",
   "metadata": {},
   "source": [
    "Finally, there are many states accounted for the in dataset. If we convert this column to a categorical variable, and create dummies, it will create a rather sparse matrix (many 0s in our dataset) becuase there will be 49 dummy variables. One alternative is to classify each state to a larger US region and use that variable instead of state. The following code will do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd769e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary mapping states to regions\n",
    "state_to_region = {\n",
    "    'Alabama': 'Southeast',\n",
    "    'Alaska': 'West',\n",
    "    'Arizona': 'West',\n",
    "    'Arkansas': 'South',\n",
    "    'California': 'West',\n",
    "    'Colorado': 'West',\n",
    "    'Connecticut': 'Northeast',\n",
    "    'Delaware': 'Northeast',\n",
    "    'District of Columbia': 'Southeast',\n",
    "    'Florida': 'Southeast',\n",
    "    'Georgia': 'Southeast',\n",
    "    'Hawaii': 'West',\n",
    "    'Idaho': 'West',\n",
    "    'Illinois': 'Midwest',\n",
    "    'Indiana': 'Midwest',\n",
    "    'Iowa': 'Midwest',\n",
    "    'Kansas': 'Midwest',\n",
    "    'Kentucky': 'South',\n",
    "    'Louisiana': 'South',\n",
    "    'Maine': 'Northeast',\n",
    "    'Maryland': 'Northeast',\n",
    "    'Massachusetts': 'Northeast',\n",
    "    'Michigan': 'Midwest',\n",
    "    'Minnesota': 'Midwest',\n",
    "    'Mississippi': 'South',\n",
    "    'Missouri': 'Midwest',\n",
    "    'Montana': 'West',\n",
    "    'Nebraska': 'Midwest',\n",
    "    'Nevada': 'West',\n",
    "    'New Hampshire': 'Northeast',\n",
    "    'New Jersey': 'Northeast',\n",
    "    'New Mexico': 'West',\n",
    "    'New York': 'Northeast',\n",
    "    'North Carolina': 'Southeast',\n",
    "    'North Dakota': 'Midwest',\n",
    "    'Ohio': 'Midwest',\n",
    "    'Oklahoma': 'South',\n",
    "    'Oregon': 'West',\n",
    "    'Pennsylvania': 'Northeast',\n",
    "    'Rhode Island': 'Northeast',\n",
    "    'South Carolina': 'Southeast',\n",
    "    'South Dakota': 'Midwest',\n",
    "    'Tennessee': 'South',\n",
    "    'Texas': 'South',\n",
    "    'Utah': 'West',\n",
    "    'Vermont': 'Northeast',\n",
    "    'Virginia': 'Southeast',\n",
    "    'Washington': 'West',\n",
    "    'West Virginia': 'South',\n",
    "    'Wisconsin': 'Midwest',\n",
    "    'Wyoming': 'West'\n",
    "}\n",
    "\n",
    "# Add a new 'Region' column based on the mapping\n",
    "diabetes['Region'] = diabetes['State'].map(state_to_region)\n",
    "\n",
    "# Print to verify'Region' column has been added\n",
    "diabetes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4007b8d1",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "Make at least two figures (feel free to make more) and explain their relevance to the scientific problem. The goal here is to uncover interesting patterns in the data, learn more about the scope of the problem, and communicate these findings to your audience in clear ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfb3ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# EDA #1 and interpretations in this section \n",
    "#-----------\n",
    "sns.scatterplot(x = \"Physical_Inactivity_Number\",\n",
    "                y = \"Diabetes_Number\",\n",
    "                data = diabetes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e31f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# EDA #2 and interpretations in this section \n",
    "#-----------\n",
    "# Sort to plot in descending order\n",
    "diabetes = diabetes.sort_values(by='Diabetes_Number', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x = \"Region\", \n",
    "            y = \"Diabetes_Number\", \n",
    "            data = diabetes);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4df05b0",
   "metadata": {},
   "source": [
    "## 3. Prepare to Fit Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73492869",
   "metadata": {},
   "source": [
    "### 3.1 Finalize Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67257021",
   "metadata": {},
   "source": [
    "We've already cleaned up the data, but we can make a few more adjustments before partitioning the data and training models. Let's recode 'Region' to be a categorical variable using `pd.get_dummies` and drop 'State'. Also, we'll drop 'County' because 'CountyFIPS' is already a unique identifier for the county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa1676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Drop and get dummies\n",
    "#-----------\n",
    "\n",
    "# create dummy features out of 'Region', which might be related to diabetes rates \n",
    "diabetes_clean = pd.get_dummies(diabetes, \n",
    "                                columns = ['Region'],  \n",
    "                                drop_first = True) # drop the first as a reference \n",
    "\n",
    "# drop 'County' and 'State' variables\n",
    "diabetes_clean = diabetes_clean.drop(labels = ['County', 'State'],\n",
    "                               axis = 1)\n",
    "\n",
    "# look at first 10 rows of new data frame \n",
    "diabetes_clean.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c768ecd6",
   "metadata": {},
   "source": [
    "### 3.2 Partition Data, Feature Selection, and Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f305051f",
   "metadata": {},
   "source": [
    "Now, we will partition our data to prepare it for the training process. Ultimately we want to use a 60% train—20% validation—20% test in this case. More data in the training set lowers bias, but then increases variance in the validation/test sets. Balancing between bias and variance with choice of these set sizes is important as we want to ensure that there is enough data to train on to get good predictions, but also want to make sure our hold-out sets are representative enough.\n",
    "\n",
    "Work through partitioning the data into the test/train/validation sets in the chunks below. Be sure to that if you are using Ridge or LASSO, you Standardize the data. Where you do this in the workflow matters so be clear about where you are doing this and why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28c192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Partition data\n",
    "#-----------\n",
    "\n",
    "# create y dataframe \n",
    "y = diabetes_clean.Diabetes_Number\n",
    "\n",
    "# create X dataframe (include everything except \"Diabetes_Number\", our target, \n",
    "# and \"race alone or in combination with one or more other races_total population\")\n",
    "X  = diabetes_clean.drop(['Diabetes_Number', 'race alone or in combination with one or more other races_total population'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56216906",
   "metadata": {},
   "source": [
    "Dropped features (justification)  \n",
    "One race (Likely colinear with other race variable. Keeping \"race alone or in combo\")\n",
    "race alone or in combination ()\n",
    "citizen-voting age population (likely colinear with other age variables)  \n",
    "Sex ratios (Too homogenous throught dataset)  \n",
    "2+ races (Likely colinear with other race variables)  \n",
    "age categories with no upper or lower bounds (Not very informative in my opinion as a demographer)  \n",
    "median age (not informative as it was divided by population count)   \n",
    "Race subcategories () "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed567cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Feature selection\n",
    "#-----------\n",
    "X = X.drop(['race_total population', 'hispanic or latino and race_total population_not hispanic or latino'] + list(X.filter(regex='one race|citizen|ratio|race alone or in combination with one or more other races|two or more races|years and over|median|mexican|puerto|cuban|other hispanic or latino|under 18')), axis = 1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f0541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Training/test split\n",
    "#-----------\n",
    "\n",
    "# set seed\n",
    "np.random.seed(10)\n",
    "\n",
    "# split and return X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,  \n",
    "                                                    y,        \n",
    "                                                    train_size=0.8, \n",
    "                                                    test_size=0.2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987b8243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Validation split\n",
    "#-----------\n",
    "\n",
    "# 60-20-20 train-validate-test split\n",
    "X_train, X_validate, y_train, y_validate =  train_test_split(X_train,\n",
    "                                                             y_train,\n",
    "                                                             train_size=0.75,\n",
    "                                                             test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cc8a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Standardization\n",
    "#-----------\n",
    "# Given that we want to only standardize non-dichotomous variables, we need to find a \n",
    "# solution that will loop over only the columns we want to standardize. The code below\n",
    "# identifies all non-dichotomous variables in our dataset and only standardizes those.\n",
    "\n",
    "# load library and create instance of Standard Scaler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# identify non-dichotomous columns we want to transform\n",
    "columns = list(X_test.select_dtypes(include=['number']).loc[:, X_test.nunique() > 2])\n",
    "\n",
    "# use loop to transform training data for only columns we want to transform\n",
    "for column in columns:\n",
    "    X_train[column] = scaler.fit_transform(X_train[column].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# use loop to transform validation data for only columns we want to transform\n",
    "for column in columns:\n",
    "    X_validate[column] = scaler.fit_transform(X_validate[column].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# use loop to transform test data for only columns we want to transform\n",
    "for column in columns:\n",
    "    X_test[column] = scaler.fit_transform(X_test[column].values.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e762cb",
   "metadata": {},
   "source": [
    "## 4. Train Models\n",
    "\n",
    "In this section, train your models. \n",
    "\n",
    "**Note that if you use Lasso, you will likely need to specify a very low penalty (e.g., an alpha of 0.001) because of convergence problems.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1836726",
   "metadata": {},
   "source": [
    "### 4.1 Describe models\n",
    "\n",
    "Detail the basic logic and assumptions underlying each model, its pros/cons, and why it is a plausible choice for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3818c2",
   "metadata": {},
   "source": [
    "**MODEL DESCRIPTION(S):**  \n",
    "Model 1: Linear Regression. \n",
    "\n",
    "Model 2: Ridge Regression.\n",
    "\n",
    "Model 3: LASSO Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b90463",
   "metadata": {},
   "source": [
    "### 4.2 Train models\n",
    "\n",
    "Train each model in the training set, and be sure to tune hyperparameters if appropriate. Report any relevant summary statistics from the training set, including how well each model fits the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5fb8ca",
   "metadata": {},
   "source": [
    "#### Model 1: Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ddd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# training linear model\n",
    "#-----------\n",
    "\n",
    "# create model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# fit the model\n",
    "lin_model = lin_reg.fit(X_train, y_train)\n",
    "\n",
    "lin_reg_data = pd.DataFrame([lin_model.coef_, X.columns]).T  # create a dataframe from the estimates\n",
    "lin_reg_data.columns = ['Coefficient', 'Feature']           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edf7f94-8f30-4aeb-bdc8-d1773e73bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning hyperparameters\n",
    "# specify the hyperparameters\n",
    "param_grid = {'fit_intercept': [True, False]}           # use dictionary for tuning\n",
    "\n",
    "# execute the grid search\n",
    "lin_grid_reg = GridSearchCV(estimator  = lin_reg,      # model to be tuned\n",
    "                            param_grid = param_grid,   # parameters to be searched as specified above\n",
    "                            cv=3)                      # 3-fold cross-validation to be used during hypertuning\n",
    "\n",
    "# now fit the tuning on the training data\n",
    "lin_grid_reg.fit(X_train, y_train)\n",
    "\n",
    "# select the best performing model and predict with that on validation dataset\n",
    "best_index = np.argmax(lin_grid_reg.cv_results_[\"mean_test_score\"])  # find the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40593c7f-c614-4b5b-adaf-76d64d901456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5988697f",
   "metadata": {},
   "source": [
    "#### Model 2: Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Model 2 training\n",
    "#-----------\n",
    "\n",
    "# create model\n",
    "ridge_reg = Ridge()                                          \n",
    "\n",
    "ridge_model = ridge_reg.fit(X_train, y_train)                    # fit model\n",
    "\n",
    "ridge_reg_data = pd.DataFrame([ridge_model.coef_, X.columns]).T  # create df from estimates\n",
    "ridge_reg_data.columns = ['Coefficient', 'Feature']              # col names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dcab93-098e-4ac7-8335-8998bc18e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the hyperparameters\n",
    "param_grid = {'alpha': np.arange(.1, 1, .1),\n",
    "              'fit_intercept': [True, False],\n",
    "              'solver': ['auto', 'svd', 'cholesky', 'lsqr']}\n",
    "\n",
    "# execute the grid search\n",
    "ridge_grid_reg = GridSearchCV(ridge_reg,  # model to be tuned\n",
    "                              param_grid, # parameters to be searched as specified above\n",
    "                              cv=3)       # 3-fold cross-validation to be used during hypertuning\n",
    "\n",
    "# fit the tuning on the training data\n",
    "ridge_grid_reg.fit(X_train, y_train)\n",
    "\n",
    "# select the best performing model and predict with that on validation dataset \n",
    "best_index = np.argmax(ridge_grid_reg.cv_results_[\"mean_test_score\"])  # find the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597bff0-f108-484c-be39-d52a39717006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fb1f5e8",
   "metadata": {},
   "source": [
    "#### Model 3: LASSO regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e375f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Model 3 training\n",
    "#-----------\n",
    "\n",
    "# create model\n",
    "lasso_reg = Lasso(max_iter=15000)\n",
    "\n",
    "lasso_model = lasso_reg.fit(X_train, y_train)                    # fit model\n",
    "\n",
    "lasso_reg_data = pd.DataFrame([lasso_model.coef_, X.columns]).T  # create a dataframe from the estimates\n",
    "lasso_reg_data.columns = ['Coefficient', 'Feature']              # add column names for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a343427-4b81-4a87-ac5b-a307469fa973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the hyperparameters\n",
    "param_grid = {'alpha': np.arange(.1, 1, .1),\n",
    "              'fit_intercept': [True, False],\n",
    "              'selection': ['cyclic', 'random']}\n",
    "\n",
    "# execute the grid search\n",
    "lasso_grid_reg = GridSearchCV(lasso_reg,  # model to be tuned\n",
    "                              param_grid, # parameters to be searched as specified above\n",
    "                              cv=3)       # 3-fold cross-validation to be used during hypertuning\n",
    "\n",
    "# now fit the tuning on the training data\n",
    "lasso_grid_reg.fit(X_train, y_train)\n",
    "\n",
    "# select the best performing model and predict with that on validation dataset \n",
    "best_index = np.argmax(lasso_grid_reg.cv_results_[\"mean_test_score\"])   # find the best performing model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02711ee5",
   "metadata": {},
   "source": [
    "## 5. Validate and Refine Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7738d9",
   "metadata": {},
   "source": [
    "### 5.1 Predict on the validation set\n",
    "Using each of the models you trained, predict outcomes in the validation set. Evaluate how well each model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d578f438-e83d-49cb-8ac4-e1e58e3982a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to calculate the root mean squared errror\n",
    "def rmse(pred, actual):\n",
    "    return np.sqrt(np.mean((pred - actual) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f906b8-2a29-4e14-bc1c-4d1eeb4a958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Predict on validation data\n",
    "#-----------\n",
    "best_lin_pred = lin_grid_reg.best_estimator_.predict(X_validate)     # find best estimator and predict on validate\n",
    "\n",
    "# results  \n",
    "print(lin_grid_reg.cv_results_[\"params\"][best_index])\n",
    "print('Best CV R^2:', max(lin_grid_reg.cv_results_[\"mean_test_score\"]))\n",
    "print('Validation R^2:', lin_grid_reg.score(X_validate, y_validate))\n",
    "print('Validation RMSE', rmse(best_lin_pred, y_validate))\n",
    "\n",
    "# plot the residuals on a scatter plot\n",
    "plt.scatter(y_validate, best_lin_pred)                    # specify x and y of the scatter plot\n",
    "plt.title('Linear Model: Predicted vs Actual')  # specify plot title\n",
    "plt.xlabel('actual value')                           # specify x-axis label\n",
    "plt.ylabel('predicted value')                        # specify y-axis label\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b1c5af-d5dd-429a-97d8-c0a04a6ce3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Predict on validation data\n",
    "#-----------\n",
    "best_ridge_pred = ridge_grid_reg.best_estimator_.predict(X_validate)   # find best estimator and predict on validate\n",
    "\n",
    "# print the results  \n",
    "print(ridge_grid_reg.cv_results_[\"params\"][best_index])\n",
    "print('Best CV R^2:', max(ridge_grid_reg.cv_results_[\"mean_test_score\"]))\n",
    "print('Validation R^2:', ridge_grid_reg.score(X_validate, y_validate))\n",
    "print('Validation RMSE', rmse(best_ridge_pred, y_validate))\n",
    "\n",
    "# plot the residuals on a scatter plot\n",
    "plt.scatter(y_validate, best_ridge_pred)                    # specify x and y of the scatter plot\n",
    "plt.title('Ridge Model: Predicted vs Actual')  # specify plot title\n",
    "plt.xlabel('actual value')                           # specify x-axis label\n",
    "plt.ylabel('predicted value')                        # specify y-axis label\n",
    "plt.axis('equal')                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Predict on validation data\n",
    "#-----------\n",
    "best_lasso_pred = lasso_grid_reg.best_estimator_.predict(X_validate)    # find best estimator and predict on validate\n",
    "\n",
    "# results\n",
    "print(lasso_grid_reg.cv_results_[\"params\"][best_index])\n",
    "print('Best CV R^2:', max(lasso_grid_reg.cv_results_[\"mean_test_score\"]))\n",
    "print('Validation R^2:', lasso_grid_reg.score(X_validate, y_validate))\n",
    "print('Validation RMSE', rmse(best_lasso_pred, y_validate))\n",
    "\n",
    "# plot the residuals on a scatter plot\n",
    "plt.scatter(y_validate, best_lasso_pred)                    # specify x and y of the scatter plot\n",
    "plt.title('LASSO Model Predicted v. Actual')  # specify plot title\n",
    "plt.xlabel('actual value')                           # specify x-axis label\n",
    "plt.ylabel('predicted value')                        # specify y-axis label\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf13d918-d5d1-4eac-bd14-e2bd1c64872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,10))\n",
    "sns.barplot(x=\"Coefficient\",                      \n",
    "            y=\"Feature\",                     \n",
    "            data=lin_reg_data).set_title(\"Linear Coefficients\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12efdc25",
   "metadata": {},
   "source": [
    "### 5.2 Predict on the test set\n",
    "\n",
    "Now, choose your best performing model of the three, select out unimportant feature(s), retrain the model, and then predict on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58840265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Predict using your best model\n",
    "#-----------\n",
    "X = X.drop(['CountyFIPS', 'hispanic or latino and race_total population_not hispanic or latino_some other race alone'], axis = 1)\n",
    "# Linear model\n",
    "# pick the best estimator and predict on test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,  \n",
    "                                                    y,        \n",
    "                                                    train_size=0.8, \n",
    "                                                    test_size=0.2) \n",
    "\n",
    "lin_model = lin_reg.fit(X_train, y_train)\n",
    "\n",
    "lin_reg_data = pd.DataFrame([lin_model.coef_, X.columns]).T  # create a dataframe from the estimates\n",
    "lin_reg_data.columns = ['Coefficient', 'Feature']              # add column names for clarity\n",
    "\n",
    "# tuning hyperparameters\n",
    "# specify the hyperparameters\n",
    "param_grid = {'fit_intercept': [True, False]}           # use dictionary for tuning\n",
    "\n",
    "# execute the grid search\n",
    "lin_grid_reg = GridSearchCV(estimator  = lin_reg,      # model to be tuned\n",
    "                            param_grid = param_grid,   # parameters to be searched as specified above\n",
    "                            cv=3)                      # 3-fold cross-validation to be used during hypertuning\n",
    "\n",
    "# now fit the tuning on the training data\n",
    "lin_grid_reg.fit(X_train, y_train)\n",
    "\n",
    "# select the best performing model and predict with that on test set\n",
    "best_index = np.argmax(lin_grid_reg.cv_results_[\"mean_test_score\"])  # find the best performing model\n",
    "\n",
    "\n",
    "best_pred = lin_grid_reg.best_estimator_.predict(X_test)\n",
    "\n",
    "# print various results\n",
    "print('Best CV R^2:', max(lin_grid_reg.cv_results_[\"mean_test_score\"]))\n",
    "print('Test R^2:', lin_grid_reg.score(X_test, y_test))\n",
    "print('Test RMSE', rmse(best_pred, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587e3780-abe9-4799-b562-8866ff5b5ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, best_pred)                    # specify x and y of the scatter plot\n",
    "plt.title('Linear Model: Predicted vs Actual')  # specify plot title\n",
    "plt.xlabel('actual value')                           # specify x-axis label\n",
    "plt.ylabel('predicted value')                        # specify y-axis label\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79689b2a",
   "metadata": {},
   "source": [
    "### 5.3 Impement a cross-validation approach\n",
    "\n",
    "Finally, implement a cross-validation approach for your best model and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Run cross-validation\n",
    "#-----------\n",
    "\n",
    "best_model = lin_grid_reg.best_estimator_\n",
    "\n",
    "cv_score = cross_val_score(best_model, X_train, y_train, cv = 5, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "\n",
    "print('CV negative RMSE: ', cv_score)\n",
    "print('mean CV  negative RMSE: ', np.mean(cv_score))\n",
    "print('Test R^2:', test_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250994bb",
   "metadata": {},
   "source": [
    "## 6. Discussion Questions\n",
    "\n",
    "In this section, insert responses for discussion questions here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2fb212",
   "metadata": {},
   "source": [
    "1. What is bias-variance tradeoff? Why is it relevant to machine learning problems like this one?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b143ca1a",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a596d",
   "metadata": {},
   "source": [
    "2. Define overfitting, and why it matters for machine learning. How can we address it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bfab1f",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**...  \n",
    "Overfitting occurs when a model matches the training data too closely, which leads to a failure to generalize to other data. This produces high variance. When variance is high, bias is usually low (and vice-versa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e64e982",
   "metadata": {},
   "source": [
    "3. Discuss your analysis in 2-3 paragraphs. Discuss your findings and recommendations. Which counties or regions would you prioritize for the pilot program? Would your answers change based on whether you want to take into account certain features such as race, gender, or age composition in the county? How confident would you be deploying this sort of model in a real-world application – why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dd703e",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
